{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8126d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import json\n",
    "import argparse\n",
    "import re\n",
    "import base64\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import vqa.lib.utils as utils\n",
    "import vqa.datasets as datasets\n",
    "import vqa.models as models\n",
    "import vqa.models.convnets as convnets\n",
    "from vqa.datasets.vqa_processed import tokenize_mcb\n",
    "\n",
    "def load_checkpoint(model, optimizer, path_ckpt):\n",
    "    path_ckpt_info  = path_ckpt + '_info.pth.tar'\n",
    "    path_ckpt_model = path_ckpt + '_model.pth.tar'\n",
    "    path_ckpt_optim = path_ckpt + '_optim.pth.tar'\n",
    "    if os.path.isfile(path_ckpt_info):\n",
    "        info = torch.load(path_ckpt_info)\n",
    "        start_epoch = 0\n",
    "        best_acc1   = 0\n",
    "        exp_logger  = None\n",
    "        if 'epoch' in info:\n",
    "            start_epoch = info['epoch']\n",
    "        else:\n",
    "            print('Warning train.py: no epoch to resume')\n",
    "        if 'best_acc1' in info:\n",
    "            best_acc1 = info['best_acc1']\n",
    "        else:\n",
    "            print('Warning train.py: no best_acc1 to resume')\n",
    "        if 'exp_logger' in info:\n",
    "            exp_logger = info['exp_logger']\n",
    "        else:\n",
    "            print('Warning train.py: no exp_logger to resume')\n",
    "    else:\n",
    "        print(\"Warning train.py: no info checkpoint found at '{}'\".format(path_ckpt_info))\n",
    "    if os.path.isfile(path_ckpt_model):\n",
    "        model_state = torch.load(path_ckpt_model)\n",
    "        model.load_state_dict(model_state)\n",
    "    else:\n",
    "        print(\"Warning train.py: no model checkpoint found at '{}'\".format(path_ckpt_model))\n",
    "    if optimizer is not None and os.path.isfile(path_ckpt_optim):\n",
    "        optim_state = torch.load(path_ckpt_optim)\n",
    "        optimizer.load_state_dict(optim_state)\n",
    "    else:\n",
    "        print(\"Warning train.py: no optim checkpoint found at '{}'\".format(path_ckpt_optim))\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {}, best_acc1 {})\"\n",
    "              .format(path_ckpt, start_epoch, best_acc1))\n",
    "    return start_epoch, best_acc1, exp_logger\n",
    "\n",
    "def process_question(question_str, trainset):\n",
    "    question_tokens = tokenize_mcb(question_str)\n",
    "    question_data = torch.LongTensor(1, len(question_tokens))\n",
    "    for i, word in enumerate(question_tokens):\n",
    "        if word in trainset.word_to_wid:\n",
    "            question_data[0][i] = trainset.word_to_wid[word]\n",
    "        else:\n",
    "            question_data[0][i] = trainset.word_to_wid['UNK']\n",
    "    if torch.cuda.is_available():\n",
    "        question_data = question_data.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        question_input = Variable(question_data, volatile=True)\n",
    "    #print('question', question_str, question_tokens, question_data)\n",
    "    \n",
    "    return question_input\n",
    "\n",
    "def process_answer(answer_var, trainset, model):\n",
    "    with torch.no_grad():\n",
    "        answer_sm = torch.nn.functional.softmax(answer_var.data[0].cpu(), dim=0)\n",
    "        max_, aid = answer_sm.topk(5, 0, True, True)\n",
    "    ans = []\n",
    "    val = []\n",
    "    for i in range(5):\n",
    "        ans.append(trainset.aid_to_ans[aid.data[i]])\n",
    "        val.append(max_.data[i].cpu().item())\n",
    "    \"\"\"\n",
    "    att = []\n",
    "    for x_att in model.list_att:\n",
    "        img = x_att.view(1,14,14).cpu()\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        buffer_ = BytesIO()\n",
    "        img.save(buffer_, format=\"PNG\")\n",
    "        img_str = base64.b64encode(buffer_.getvalue()).decode()\n",
    "        img_str = 'data:image/png;base64,'+img_str\n",
    "        att.append(img_str)\n",
    "        buffer_.close()\n",
    "    \"\"\"\n",
    "    answer = {'ans':ans,'val':val} # 'att': att\n",
    "    answer_str = json.dumps(answer)\n",
    "\n",
    "    return answer_str\n",
    "\n",
    "def process_visual(visual_pil,transform, options, cnn):\n",
    "    #visual_strb64 = re.sub('^data:image/.+;base64,', '', visual_strb64)\n",
    "    #visual_PIL = Image.open(BytesIO(base64.b64decode(visual_strb64)))\n",
    "    visual_PIL = visual_pil\n",
    "    visual_tensor = transform(visual_PIL)\n",
    "    visual_data = torch.FloatTensor(1, 3,\n",
    "                                       visual_tensor.size(1),\n",
    "                                       visual_tensor.size(2))\n",
    "    visual_data[0][0] = visual_tensor[0]\n",
    "    visual_data[0][1] = visual_tensor[1]\n",
    "    visual_data[0][2] = visual_tensor[2]\n",
    "    #visual_data = visual_pil\n",
    "    #print('visual', visual_data.size(), visual_data.mean())\n",
    "    if torch.cuda.is_available():\n",
    "        visual_data = visual_data.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        visual_input = Variable(visual_data, volatile=True)\n",
    "        visual_features = cnn(visual_input)\n",
    "    if 'NoAtt' in options['model']['arch']:\n",
    "        nb_regions = visual_features.size(2) * visual_features.size(3)\n",
    "        with torch.no_grad():\n",
    "            visual_features = visual_features.sum(3).sum(2).div(nb_regions).view(-1, 2048)\n",
    "    return visual_features\n",
    "\n",
    "class MutanAttInference():\n",
    "    \"\"\"\n",
    "    MutanAtt model wrapper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dir_logs='logs/vqa/mutan_att_trainval', config='options/vqa/mutan_att_trainval.yaml', resume='ckpt'):\n",
    "        self.options = {\n",
    "            'logs': {\n",
    "                'dir_logs': dir_logs\n",
    "            }\n",
    "        }\n",
    "        with open(config, 'r') as handle:\n",
    "            options_yaml = yaml.load(handle)\n",
    "        self.options = utils.update_values(self.options, options_yaml)\n",
    "        \n",
    "        self.trainset = datasets.factory_VQA(self.options['vqa']['trainsplit'],\n",
    "                                        self.options['vqa'])\n",
    "\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(self.options['coco']['size']),\n",
    "            transforms.CenterCrop(self.options['coco']['size']),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        opt_factory_cnn = {\n",
    "            'arch': self.options['coco']['arch']\n",
    "            }\n",
    "        self.cnn = convnets.factory(opt_factory_cnn, cuda=torch.cuda.is_available(), data_parallel=False)\n",
    "\n",
    "        self.model = models.factory(\n",
    "            self.options['model'],\n",
    "            self.trainset.vocab_words(),\n",
    "            self.trainset.vocab_answers(),\n",
    "            cuda=torch.cuda.is_available(),\n",
    "            data_parallel=False\n",
    "            )\n",
    "        start_epoch, best_acc1, _ = load_checkpoint(self.model, None,\n",
    "            os.path.join(self.options['logs']['dir_logs'], resume))\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        with torch.no_grad():\n",
    "            self.model.seq2vec.register_forward_hook(get_activation('seq2vec'))\n",
    "            self.model.conv_att.register_forward_hook(get_activation('conv_att'))\n",
    "        self.activation = activation\n",
    "        \n",
    "    def interpolate(self, img, heat_map):\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        # resize heat map\n",
    "        heat_map_resized = transform.resize(heat_map, (height, width,1))\n",
    "        # normalize\n",
    "        max_value = np.max(heat_map_resized)\n",
    "        min_value = np.min(heat_map_resized)\n",
    "        normalized_heat_map = (heat_map_resized - min_value) / (max_value - min_value)\n",
    "        return normalized_heat_map\n",
    "\n",
    "    def grad_cam(self, img, logits, activations, sigma=1):\n",
    "        img = img.permute(1,2,0)\n",
    "        relu = torch.nn.ReLU()\n",
    "        pred = logits.argmax(dim=1)\n",
    "        logits[:,pred.item()].backward()\n",
    "        gradients = self.model.conv_att.weight.grad\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0,2,3])\n",
    "        for i in range(2):\n",
    "            activations[:, i, :, :] *= pooled_gradients[i]\n",
    "        activations = relu(activations)\n",
    "\n",
    "        heat = torch.mean(activations, dim=1).squeeze()\n",
    "        heat = ndimage.filters.gaussian_filter(heat.cpu(), sigma=sigma)\n",
    "\n",
    "        heat = self.interpolate(np.array(img), 1 * heat)\n",
    "        #heat[heat < 0.1] = 0\n",
    "        #heat[heat < 0.5] *= 0.5\n",
    "        heat = torch.Tensor(heat)\n",
    "        fg_im = (heat * img).permute(2,0,1)\n",
    "        bg_im = ((1-heat) * img).permute(2,0,1)\n",
    "        \n",
    "        return heat, fg_im[None,:,:], bg_im[None,:,:]\n",
    "    \n",
    "    def infer(self, img, question):\n",
    "        \"\"\"\n",
    "        :param img: PIL image object\n",
    "        :param question (str): \n",
    "\n",
    "        Returns:\n",
    "            The top five answers, the final logits weight vector, the question embedding, and the attention map\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            v = process_visual(img, self.transform, self.options, self.cnn)\n",
    "            q = process_question(question, self.trainset)\n",
    "        \n",
    "        # get the output after the first layer\n",
    "        logits = self.model(v,q) # logit weight vector of the answers\n",
    "        a = process_answer(logits, self.trainset, self.model)\n",
    "        \n",
    "        q_emb = self.activation['seq2vec']\n",
    "        att_activation = self.activation['conv_att']\n",
    "        del v, q\n",
    "        return a, logits, q_emb, att_activation\n",
    "    \n",
    "    \n",
    "class MutanAttInference2():\n",
    "    \"\"\"\n",
    "    MutanAtt model wrapper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes_idxs=None, dir_logs='logs/vqa/mutan_att_trainval', config='options/vqa/mutan_att_trainval.yaml', resume='ckpt'):\n",
    "        self.options = {\n",
    "            'logs': {\n",
    "                'dir_logs': dir_logs\n",
    "            }\n",
    "        }\n",
    "        with open(config, 'r') as handle:\n",
    "            options_yaml = yaml.load(handle)\n",
    "        self.options = utils.update_values(self.options, options_yaml)\n",
    "        \n",
    "        self.trainset = datasets.factory_VQA(self.options['vqa']['trainsplit'],\n",
    "                                        self.options['vqa'])\n",
    "\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(self.options['coco']['size']),\n",
    "            transforms.CenterCrop(self.options['coco']['size']),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        opt_factory_cnn = {\n",
    "            'arch': self.options['coco']['arch']\n",
    "            }\n",
    "        self.cnn = convnets.factory(opt_factory_cnn, cuda=torch.cuda.is_available(), data_parallel=False)\n",
    "\n",
    "        self.model = models.factory(\n",
    "            self.options['model'],\n",
    "            self.trainset.vocab_words(),\n",
    "            self.trainset.vocab_answers(),\n",
    "            cuda=torch.cuda.is_available(),\n",
    "            data_parallel=False\n",
    "            )\n",
    "        start_epoch, best_acc1, _ = load_checkpoint(self.model, None,\n",
    "            os.path.join(self.options['logs']['dir_logs'], resume))\n",
    "        self.classes = classes_idxs\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        with torch.no_grad():\n",
    "            self.model.seq2vec.register_forward_hook(get_activation('seq2vec'))\n",
    "            self.model.conv_att.register_forward_hook(get_activation('conv_att'))\n",
    "        self.activation = activation\n",
    "\n",
    "    def interpolate(self, img, heat_map):\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        # resize heat map\n",
    "        heat_map_resized = transform.resize(heat_map, (height, width,1))\n",
    "        # normalize\n",
    "        max_value = np.max(heat_map_resized)\n",
    "        min_value = np.min(heat_map_resized)\n",
    "        normalized_heat_map = (heat_map_resized - min_value) / (max_value - min_value)\n",
    "        return normalized_heat_map\n",
    "\n",
    "    def grad_cam(self, img, logits, activations):\n",
    "        img = img.permute(1,2,0)\n",
    "        relu = torch.nn.ReLU()\n",
    "        pred = logits.argmax(dim=1)\n",
    "        logits[:,pred.item()].backward()\n",
    "        gradients = self.model.conv_att.weight.grad\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0,2,3])\n",
    "        for i in range(2):\n",
    "            activations[:, i, :, :] *= pooled_gradients[i]\n",
    "        activations = relu(activations)\n",
    "\n",
    "        heat = torch.mean(activations, dim=1).squeeze()\n",
    "        heat = ndimage.filters.gaussian_filter(heat.cpu(), sigma=0)\n",
    "\n",
    "        heat = self.interpolate(np.array(img), 1 * heat)\n",
    "        heat[heat < 0.1] = 0\n",
    "        heat = torch.Tensor(heat)\n",
    "        fg_im = (heat * img).permute(2,0,1)\n",
    "        bg_im = ((1.-heat) * img).permute(2,0,1)\n",
    "        \n",
    "        return heat, fg_im[None,:,:], bg_im[None,:,:]\n",
    "    \n",
    "    def infer(self, img, question):\n",
    "        \"\"\"\n",
    "        :param img: PIL image object\n",
    "        :param question (str): \n",
    "\n",
    "        Returns:\n",
    "            The top five answers, the final logits weight vector, and the question embedding\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            v = process_visual(img, self.transform, self.options, self.cnn)\n",
    "            q = process_question(question, self.trainset)\n",
    "        \n",
    "        # get the output after the first layer\n",
    "        \n",
    "        logits = self.model(v,q) # logit weight vector of the answers\n",
    "        a = process_answer(logits, self.trainset, self.model)\n",
    "\n",
    "        #logits_cls = torch.clone(logits)\n",
    "        #logits_cls = logits_cls.cpu().detach().numpy()[:,self.classes]\n",
    "        #logits_cls = torch.Tensor(logits_cls).to(\"cuda\")\n",
    "        q_emb = self.activation['seq2vec']\n",
    "        att_activation = self.activation['conv_att']\n",
    "        \n",
    "        del v,q\n",
    "        return a, logits, q_emb, att_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264811c",
   "metadata": {},
   "source": [
    "You must use pip==1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ac72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-022dcaa06c96>:140: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  options_yaml = yaml.load(handle)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b26faeb74dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMutanAttInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_logs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs/vqa/mutan_att_trainval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'options/vqa/mutan_att_trainval.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-022dcaa06c96>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dir_logs, config, resume)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions_yaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         self.trainset = datasets.factory_VQA(self.options['vqa']['trainsplit'],\n\u001b[0m\u001b[1;32m    144\u001b[0m                                         self.options['vqa'])\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/VQA/vqa_pytorch/vqa/datasets/vqa.py\u001b[0m in \u001b[0;36mfactory\u001b[0;34m(data_split, opt, opt_coco, opt_vgenome)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'VQA'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'2'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mdataset_vqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVQA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'VQA2'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'2'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mdataset_vqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVQA2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/VQA/vqa_pytorch/vqa/datasets/vqa.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_split, opt, dataset_img)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVQA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/VQA/vqa_pytorch/vqa/datasets/vqa.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_split, opt, dataset_img)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAbstractVQA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# means self.data_split is 'val' or 'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/VQA/vqa_pytorch/vqa/datasets/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_split, opt, dataset_img)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from medcam import medcam\n",
    "print(np.__version__)\n",
    "#np_load_old = np.load\n",
    "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "#with torch.no_grad():\n",
    "model = MutanAttInference(dir_logs='logs/vqa/mutan_att_trainval', config='options/vqa/mutan_att_trainval.yaml')\n",
    "model.model.to(\"cuda:0\")\n",
    "    \n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "gen_files = glob.glob(\"../../model/evaluation/training/y_gen_q*.png\")\n",
    "gen_files.sort(key=os.path.getmtime,reverse=True)\n",
    "orig_files = glob.glob(\"../../model/evaluation/training/orig_q*.png\")\n",
    "orig_files.sort(key=os.path.getmtime, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08064146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "rx = r'(\\{[^{}]+\\})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e853a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import cv2\n",
    "#url = \"http://images.cocodataset.org/train2017/000000505539.jpg\"\n",
    "idx = 10\n",
    "\n",
    "q = json.loads(re.search(rx, gen_files[idx])[0].replace(\"'\", \"\\\"\"))[\"question\"]\n",
    "print(q)\n",
    "orig = Image.open(orig_files[idx])\n",
    "gen = Image.open(gen_files[idx])\n",
    "\n",
    "#img = Image.open(\"../../model/evaluation/training/orig_q_{'question': 'What color is the sofa?', 'image_id': 200305, 'question_id': 2003051} brown_3.png\")\n",
    "#img1 = Image.open(\"../../model/evaluation/training/y_gen_q_{'question': 'What color is the sofa?', 'image_id': 200305, 'question_id': 2003051}_3.png\")\n",
    "#orig_img = Image.open(\"../../model/evaluation/input_qid_0_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589bc53",
   "metadata": {},
   "source": [
    "the visual feature must be of shape N x 2048 x 14 x 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cebb57",
   "metadata": {},
   "source": [
    "question embedding must be of shape N x num_worods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "a, logits_pred, q_emb, activation = model.infer(orig, q)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924ecca",
   "metadata": {},
   "source": [
    "# Grad - cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = model.model.conv_att.weight.grad\n",
    "pooled_gradients = torch.mean(gradients, dim=[0,2,3])\n",
    "for i in range(2):\n",
    "    activation[:, i, :, :] *= pooled_gradients[i]\n",
    "grad_cam(model, orig,logits_pred, activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import heatmap.heatmap as heatmap\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1923be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    activation[:, i, :, :] *= pooled_gradients[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_add(img, heat_map):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    # resize heat map\n",
    "    heat_map_resized = transform.resize(heat_map, (height, width,1))\n",
    "    # normalize\n",
    "    max_value = np.max(heat_map_resized)\n",
    "    min_value = np.min(heat_map_resized)\n",
    "    normalized_heat_map = (heat_map_resized - min_value) / (max_value - min_value)\n",
    "    return normalized_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a162f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "activation = relu(activation)\n",
    "heat = torch.mean(activation, dim=1).squeeze()\n",
    "#heat = np.maximum(heat.cpu(), 0)\n",
    "#heat /= torch.max(heat)\n",
    "heat = ndimage.filters.gaussian_filter(heat.cpu(), sigma=1)\n",
    "heat = my_add(np.array(orig),heat*(-1))\n",
    "#heat = heat*0.8\n",
    "#heat[heat < 0.5] *= 0.5\n",
    "\n",
    "heatmap.add(np.array(orig), heat, cmap=\"turbo\",axis=\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d29895",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = transform.resize(heat, (np.array(orig).shape[0], np.array(orig).shape[1], 1))\n",
    "testgrad1 = (heat * orig).astype(\"uint8\")\n",
    "testgrad2 = ((1-heat) * orig).astype(\"uint8\")\n",
    "plt.imshow(testgrad1)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e3a35",
   "metadata": {},
   "source": [
    "# heat maps that actually work <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2144504",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbca965",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = model.model.list_att\n",
    "att = sum(att)\n",
    "heat_map = np.reshape(att.cpu(), (14,14))\n",
    "heat_map = ndimage.filters.gaussian_filter(heat_map, sigma=2)\n",
    "heat_map = my_add(np.array(orig), heat_map)\n",
    "#heat_map = np.repeat(heat_map[None,:], 1, axis=2)\n",
    "\n",
    "#heatmap.add(np.array(orig), heat_map, alpha=.6, cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heat_map[heat_map<0.1] = 0.\n",
    "test1 = (heat_map*orig).astype(\"uint8\")\n",
    "test2 = (orig * (1-heat_map)).astype(\"uint8\") #uint8 is absolutely necessary!!!\n",
    "plt.imshow(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb62c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(testgrad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(img, model, sigma=2):\n",
    "    att = model.model.list_att\n",
    "    heat_maps = [np.reshape(a.cpu(),(14,14)) for a in att]\n",
    "    heat_map = sum(heat_maps) / 4\n",
    "    heat_map = heat_map = ndimage.filters.gaussian_filter(heat_map, sigma=sigma)\n",
    "    heatmap.add(np.array(img), heat_map, alpha=.6, cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = model.model.list_att\n",
    "att[0].shape\n",
    "heat_map = np.reshape(att[0].cpu(), (14,14))\n",
    "heat_map = ndimage.filters.gaussian_filter(heat_map, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f33461",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_heatmap(orig, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_maps = [np.reshape(a.cpu(),(14,14)) for a in att]\n",
    "heat_map = sum(heat_maps) / 4\n",
    "heat_map = ndimage.filters.gaussian_filter(heat_map, sigma=2)\n",
    "heatmap.add(np.array(orig), heat_map, alpha=.7, cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cace54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a2, logits_pred2, q_emb2 = model.infer(gen, q)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_heatmap(gen, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_env",
   "language": "python",
   "name": "train_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
